{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "#MNIST 함수 사용, root : 어느 경로에 있나 train : True -> train set을 불러오겠다.\n",
    "#transform : 어떤 변환 함수를 사용할 것인가? \n",
    "mnist_train = dsets.MNIST(root = \"Mnist_data/\", train = True, transform = transforms.ToTensor(), download = True)\n",
    "mnist_test = dsets.MNIST(root = \"Mnist_data/\", train = False, transform = transforms.ToTensor(), download = True)\n",
    " \n",
    "batch_size = 100\n",
    "#dataloader : 어떤 데이터를 로드할거냐, drop_last: 100으로 나눈 나머지 데이터들을 그냥 버리기\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "600\n",
      "epoch: 0001 cost =  0.535468519\n",
      "600\n",
      "600\n",
      "epoch: 0002 cost =  0.359274149\n",
      "600\n",
      "600\n",
      "epoch: 0003 cost =  0.331187546\n",
      "600\n",
      "600\n",
      "epoch: 0004 cost =  0.316578060\n",
      "600\n",
      "600\n",
      "epoch: 0005 cost =  0.307158172\n",
      "600\n",
      "600\n",
      "epoch: 0006 cost =  0.300180733\n",
      "600\n",
      "600\n",
      "epoch: 0007 cost =  0.295130193\n",
      "600\n",
      "600\n",
      "epoch: 0008 cost =  0.290851504\n",
      "600\n",
      "600\n",
      "epoch: 0009 cost =  0.287417054\n",
      "600\n",
      "600\n",
      "epoch: 0010 cost =  0.284379572\n",
      "600\n",
      "600\n",
      "epoch: 0011 cost =  0.281825185\n",
      "600\n",
      "600\n",
      "epoch: 0012 cost =  0.279800713\n",
      "600\n",
      "600\n",
      "epoch: 0013 cost =  0.277809024\n",
      "600\n",
      "600\n",
      "epoch: 0014 cost =  0.276154310\n",
      "600\n",
      "600\n",
      "epoch: 0015 cost =  0.274440855\n"
     ]
    }
   ],
   "source": [
    "linear = torch.nn.Linear(784, 10, bias = True).to(device)\n",
    "epochs = 15\n",
    "batch_size = 100  # 총 데이터가 6만장이라면, 배치 600개, batchsize : 100개\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr = 0.1)\n",
    "\n",
    "for epoch in range(epochs):  #15번동안 MNIST 전체 데이터를 가지고 학습\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader) \n",
    "    print(total_batch)\n",
    "    c = 0\n",
    "    for X,Y in data_loader: #batch size만큼의 data, label을 불러온다, 한 에폭이 될 때까지 계속 반복 (예상 : 600번)\n",
    "        c+=1\n",
    "        X = X.view(-1,28*28).to(device) # (batch_size, 676)으로 사이즈 변경\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost+= cost/total_batch\n",
    "    #print(c)\n",
    "    print(\"epoch:\",\"%04d\"%(epoch+1), \"cost = \", \"{:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8863000273704529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dlwlrma71/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/Users/dlwlrma71/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(-1,28*28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction,1) == Y_test \n",
    "    #torch.argmax : 최대값의 index반환 -> 예측 Label / dim = 1 방향으로!\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print(\"Accuracy: \", accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "r = random.randint(0,len(mnist_test)-1)\n",
    "X_single_data = mnist_test.test_data[r:r+1].view(-1,28*28).float().to(device)\n",
    "Y_single_data = mnist_test.test_labels[r:r+1].to(device)\n",
    "\n",
    "single_prediction = linear(X_single_data)\n",
    "print(torch.argmax(single_prediction,1).item())\n",
    "\n",
    "plt.imshow(mnist_test.test_data[r:r+1].view(28,28),cmap = \"Greys\", interpolation = \"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7126196026802063\n",
      "500 0.6931912899017334\n",
      "1000 0.6931604146957397\n",
      "1500 0.693139910697937\n",
      "2000 0.6930840015411377\n",
      "2500 0.6895953416824341\n",
      "3000 0.04585696756839752\n",
      "3500 0.013895146548748016\n",
      "4000 0.008052884601056576\n",
      "4500 0.0056461151689291\n",
      "5000 0.0043395026586949825\n",
      "5500 0.003520903643220663\n",
      "6000 0.002960497047752142\n",
      "6500 0.002553110709413886\n",
      "7000 0.0022437721490859985\n",
      "7500 0.0020009279251098633\n",
      "8000 0.0018052862724289298\n",
      "8500 0.0016442961059510708\n",
      "9000 0.0015095683047547936\n",
      "9500 0.0013951826840639114\n",
      "10000 0.001296805334277451\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n",
    "\n",
    "linear1 = nn.Linear(2,2,bias = True)\n",
    "linear2 = nn.Linear(2,1,bias = True)\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "model = nn.Sequential(linear1, sigmoid, linear2, sigmoid).to(device)\n",
    "\n",
    "criterion = nn.BCELoss().to(device)  # Loss Function : BCE\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    cost = criterion(hypothesis,Y) \n",
    "    \n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 500 == 0:\n",
    "        print(step, cost.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
